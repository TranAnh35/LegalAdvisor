# ğŸš€ HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng GPU Vá»›i LegalAdvisor

## Tá»•ng Quan

LegalAdvisor há»— trá»£ GPU acceleration Ä‘á»ƒ tÄƒng Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t xá»­ lÃ½. TÃ i liá»‡u nÃ y hÆ°á»›ng dáº«n cÃ¡ch cÃ i Ä‘áº·t vÃ  sá»­ dá»¥ng GPU.

## Kiá»ƒm Tra GPU Hiá»‡n Táº¡i

Cháº¡y script kiá»ƒm tra GPU:

```bash
python check_gpu.py
```

Script sáº½:
- âœ… Kiá»ƒm tra phiÃªn báº£n Python
- ğŸ”¥ Kiá»ƒm tra PyTorch GPU support
- ğŸ¤— Kiá»ƒm tra transformers GPU support
- ğŸ” Kiá»ƒm tra FAISS GPU support
- âš¡ Benchmark hiá»‡u suáº¥t GPU vs CPU

## YÃªu Cáº§u Há»‡ Thá»‘ng

### Pháº§n Cá»©ng
- **GPU NVIDIA** vá»›i CUDA support (GTX 10xx, RTX 20xx/30xx/40xx series)
- **RAM**: Tá»‘i thiá»ƒu 8GB (16GB khuyáº¿n nghá»‹)
- **á»” cá»©ng**: Tá»‘i thiá»ƒu 20GB trá»‘ng

### Pháº§n Má»m
- **Python**: 3.8+
- **CUDA Toolkit**: 11.8 hoáº·c 12.1
- **NVIDIA Drivers**: PhiÃªn báº£n má»›i nháº¥t

## CÃ i Äáº·t GPU Support

### BÆ°á»›c 1: CÃ i Äáº·t CUDA Toolkit

#### Windows
1. Táº£i CUDA Toolkit tá»«: https://developer.nvidia.com/cuda-downloads
2. Chá»n phiÃªn báº£n phÃ¹ há»£p:
   - **CUDA 11.8**: Cho GPU GTX/RTX 20xx series
   - **CUDA 12.1**: Cho GPU RTX 30xx/40xx series
3. Cháº¡y installer vá»›i quyá»n Administrator
4. Restart mÃ¡y tÃ­nh

#### Linux
```bash
# Ubuntu/Debian
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### BÆ°á»›c 2: CÃ i Äáº·t PyTorch Vá»›i CUDA

Trong environment LegalAdvisor:

```bash
# KÃ­ch hoáº¡t conda environment
conda activate LegalAdvisor

# Gá»¡ bá» phiÃªn báº£n cÅ©
pip uninstall torch torchvision torchaudio

# CÃ i Ä‘áº·t PyTorch vá»›i CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Hoáº·c CUDA 12.1 (cho GPU RTX 30xx/40xx)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### BÆ°á»›c 3: CÃ i Äáº·t FAISS GPU

```bash
# Gá»¡ bá» phiÃªn báº£n CPU
pip uninstall faiss-cpu

# CÃ i Ä‘áº·t phiÃªn báº£n GPU
pip install faiss-gpu
```

### BÆ°á»›c 4: Verify CÃ i Äáº·t

```bash
# Cháº¡y kiá»ƒm tra GPU
python check_gpu.py

# Cháº¡y launcher Ä‘á»ƒ kiá»ƒm tra
python launcher.py
```

## Hiá»‡u Suáº¥t Dá»± Kiáº¿n

### So SÃ¡nh GPU vs CPU

| Task | CPU (i7-10700K) | GPU (RTX 3060) | TÄƒng tá»‘c |
|------|----------------|----------------|----------|
| Embedding (384-dim) | ~2-3 giÃ¢y | ~0.1-0.2 giÃ¢y | **10-20x** |
| LLM Generation | ~5-10 giÃ¢y | ~0.5-1 giÃ¢y | **5-10x** |
| FAISS Search | ~1-2 giÃ¢y | ~0.05-0.1 giÃ¢y | **15-30x** |
| **Tá»•ng thá»i gian** | ~8-15 giÃ¢y | ~0.7-1.3 giÃ¢y | **6-15x** |

### YÃªu Cáº§u Bá»™ Nhá»›

| Model | CPU Memory | GPU Memory |
|-------|------------|------------|
| PhoBERT | ~500MB | ~1GB |
| GPT-2 VN | ~1GB | ~2GB |
| FAISS Index | ~2GB | ~3GB |
| **Tá»•ng cá»™ng** | ~3.5GB | ~6GB |

## Troubleshooting

### Lá»—i "CUDA out of memory"

**NguyÃªn nhÃ¢n**: GPU khÃ´ng Ä‘á»§ bá»™ nhá»› cho model
**Giáº£i phÃ¡p**:
1. Giáº£m batch size trong inference
2. Sá»­ dá»¥ng model quantization
3. TÄƒng RAM GPU hoáº·c sá»­ dá»¥ng GPU cÃ³ nhiá»u RAM hÆ¡n

### Lá»—i "No CUDA-capable device"

**NguyÃªn nhÃ¢n**: Driver NVIDIA cÅ© hoáº·c CUDA khÃ´ng tÆ°Æ¡ng thÃ­ch
**Giáº£i phÃ¡p**:
1. Cáº­p nháº­t NVIDIA drivers
2. CÃ i Ä‘áº·t láº¡i CUDA Toolkit
3. Restart mÃ¡y tÃ­nh

### Lá»—i "DLL load failed"

**NguyÃªn nhÃ¢n**: PyTorch vÃ  CUDA version khÃ´ng tÆ°Æ¡ng thÃ­ch
**Giáº£i phÃ¡p**:
1. Gá»¡ bá» PyTorch: `pip uninstall torch torchvision torchaudio`
2. CÃ i Ä‘áº·t láº¡i vá»›i version phÃ¹ há»£p
3. Äáº£m báº£o CUDA Toolkit Ä‘Æ°á»£c cÃ i Ä‘áº·t Ä‘Ãºng

## Cáº¥u HÃ¬nh NÃ¢ng Cao

### Quantization

Äá»ƒ giáº£m bá»™ nhá»› GPU, sá»­ dá»¥ng 4-bit quantization:

```python
# Trong legal_rag.py
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)
```

### Multi-GPU Support

LegalAdvisor há»— trá»£ multi-GPU:

```python
# Tá»± Ä‘á»™ng phÃ¢n bá»• model lÃªn nhiá»u GPU
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",  # Tá»± Ä‘á»™ng phÃ¢n bá»•
    quantization_config=quantization_config
)
```

## Monitoring GPU Usage

### Sá»­ Dá»¥ng nvidia-smi

```bash
# Xem usage GPU real-time
nvidia-smi -l 1

# Xem processes sá»­ dá»¥ng GPU
nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv
```

### Trong Code

```python
import torch

# Xem GPU memory usage
print(f"GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB used")
print(f"GPU Memory: {torch.cuda.memory_reserved()/1024**3:.2f}GB reserved")
```

## FAQ

### Q: TÃ´i cÃ³ thá»ƒ cháº¡y LegalAdvisor khÃ´ng cÃ³ GPU?

**A**: CÃ³, LegalAdvisor sáº½ tá»± Ä‘á»™ng chuyá»ƒn vá» CPU mode. Tuy nhiÃªn hiá»‡u suáº¥t sáº½ cháº­m hÆ¡n nhiá»u.

### Q: GPU nÃ o Ä‘Æ°á»£c khuyáº¿n nghá»‹?

**A**: RTX 3060 trá»Ÿ lÃªn vá»›i tá»‘i thiá»ƒu 8GB VRAM. RTX 4070 hoáº·c A-series cho hiá»‡u suáº¥t tá»‘t nháº¥t.

### Q: CÃ³ thá»ƒ sá»­ dá»¥ng AMD GPU?

**A**: Hiá»‡n táº¡i chÆ°a há»— trá»£. LegalAdvisor chá»‰ há»— trá»£ NVIDIA GPU vá»›i CUDA.

### Q: LÃ m sao Ä‘á»ƒ biáº¿t GPU cÃ³ hoáº¡t Ä‘á»™ng?

**A**: Cháº¡y `python check_gpu.py` vÃ  xem benchmark. Náº¿u speedup > 2x thÃ¬ GPU hoáº¡t Ä‘á»™ng tá»‘t.

## Support

Náº¿u gáº·p váº¥n Ä‘á» vá»›i GPU setup:

1. Cháº¡y `python check_gpu.py` Ä‘á»ƒ diagnose
2. Kiá»ƒm tra logs trong `logs/` folder
3. Táº¡o issue trÃªn GitHub vá»›i thÃ´ng tin:
   - GPU model
   - CUDA version
   - PyTorch version
   - Output cá»§a `check_gpu.py`

---

ğŸ¯ **Má»¥c tiÃªu**: LegalAdvisor vá»›i GPU sáº½ xá»­ lÃ½ cÃ¢u há»i phÃ¡p luáº­t chá»‰ trong **1-2 giÃ¢y** thay vÃ¬ **10-15 giÃ¢y** vá»›i CPU!
