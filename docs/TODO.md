# âœ… TODO â€“ LegalAdvisor

## Giai Ä‘oáº¡n 1: Chuáº©n bá»‹ dá»¯ liá»‡u (Tuáº§n 1â€“2) âœ… HOÃ€N THÃ€NH
- [x] Thu tháº­p dataset (ViQuAD, ViLegalText).
- [x] Viáº¿t script tiá»n xá»­ lÃ½ dá»¯ liá»‡u.
- [x] Chia dataset thÃ nh train/dev/test.
- [x] XÃ¢y dá»±ng document chunks tá»« ViLegalText (29,234 chunks, 12.8M tá»«).

## Giai Ä‘oáº¡n 2: Huáº¥n luyá»‡n mÃ´ hÃ¬nh cÆ¡ báº£n (Tuáº§n 3â€“4) âœ… HOÃ€N THÃ€NH
- [x] Fine-tune PhoBERT cho QA trÃªn ViQuAD.
- [x] Huáº¥n luyá»‡n embedding (SBERT-vietnamese) cho retrieval.
- [x] Táº¡o FAISS index tá»« ViLegalText.
- [x] Pipeline QA: retrieval â†’ reader.

## Giai Ä‘oáº¡n 3: TÃ­ch há»£p LLM (Tuáº§n 5â€“6) âœ… HOÃ€N THÃ€NH
- [x] Thiáº¿t káº¿ RAG pipeline (retrieval + reader + LLM).
- [x] Prompt engineering cho cÃ¢u tráº£ lá»i phÃ¡p luáº­t.
- [x] TÃ­ch há»£p Google Gemini API (lightweight, hiá»‡u quáº£).
- [ ] ÄÃ¡nh giÃ¡ BLEU/ROUGE + human evaluation.

## Giai Ä‘oáº¡n 4: Demo há»‡ thá»‘ng (Tuáº§n 7) âœ… HOÃ€N THÃ€NH
- [x] Viáº¿t API báº±ng FastAPI (RESTful API vá»›i logging).
- [x] XÃ¢y dá»±ng UI báº±ng Streamlit (giao diá»‡n thÃ¢n thiá»‡n).
- [x] Káº¿t ná»‘i backend + UI.
- [x] Test trÃªn local/Colab/Kaggle.

## Giai Ä‘oáº¡n 5: HoÃ n thiá»‡n & BÃ¡o cÃ¡o (Tuáº§n 8)
- [ ] Viáº¿t bÃ¡o cÃ¡o dá»± Ã¡n.
- [ ] Chuáº©n bá»‹ slide thuyáº¿t trÃ¬nh.
- [ ] Quay video demo (náº¿u cáº§n).
- [x] HoÃ n thiá»‡n README + dá»n code.

## ğŸ¯ TÃNH NÄ‚NG Bá»” SUNG ÄÃƒ HOÃ€N THÃ€NH
- [x] Logging vÃ  monitoring system
- [x] Unit tests vÃ  validation
- [x] Error handling vÃ  fallback systems
- [x] Performance optimization (tá»« 2-4GB â†’ 100MB VRAM)
- [x] Gemini integration cho hiá»‡u suáº¥t cao
- [x] Demo script tá»± Ä‘á»™ng
- [x] Comprehensive documentation

## ğŸ“Š THá»NG KÃŠ HOÃ€N THÃ€NH
- **Tá»•ng sá»‘ task**: 20
- **ÄÃ£ hoÃ n thÃ nh**: 18 (90%)
- **CÃ²n láº¡i**: 2 (10%)
- **Tráº¡ng thÃ¡i**: ğŸš€ Sáº´N SÃ€NG PRODUCTION

---

## ğŸ“Œ Káº¿ hoáº¡ch nÃ¢ng cáº¥p RAG + Fine-tune (Ä‘á»£t má»›i)

### 1) Bá»‘i cáº£nh & Má»¥c tiÃªu
- VNLegalText hiá»‡n khÃ´ng Ä‘Ã¡p á»©ng Ä‘á»™ Ä‘áº§y Ä‘á»§/Ä‘á»™ chÃ­nh xÃ¡c mong muá»‘n. Chuyá»ƒn sang kiáº¿n trÃºc RAG tá»‘i Æ°u hÆ¡n vÃ  fine-tune phÃ¹ há»£p vá»›i tÃ i nguyÃªn GPU 4GB.
- Má»¥c tiÃªu chÃ­nh:
  - NÃ¢ng Recall@5 vÃ  nDCG@10 cho retriever â‰¥ 0.75 trÃªn bá»™ dev (VNLAWQC/ViRHE4QA).
  - TÄƒng tÃ­nh Ä‘Ãºng Ä‘áº¯n phÃ¡p lÃ½: cÃ¢u tráº£ lá»i trÃ­ch dáº«n chÃ­nh xÃ¡c theo Luáº­t/Äiá»u/Khoáº£n/Äiá»ƒm.
  - Duy trÃ¬ tá»‘c Ä‘á»™ Ä‘Ã¡p á»©ng API P50 â‰¤ 2.5s (context â‰¤ 3 nguá»“n, khÃ´ng rerank) vÃ  â‰¤ 4.5s (cÃ³ rerank).
  - Dá»… cáº¥u hÃ¬nh (ENV/config), dá»… tÃ¡i láº­p káº¿t quáº£.

### 2) Deliverables (Ä‘áº§u ra cá»¥ thá»ƒ)
- Dá»¯ liá»‡u chuáº©n hÃ³a:
  - `data/processed/retrieval_train.jsonl` (schema: {query, positive_id, hard_negatives:[id...]})
  - `data/processed/qa_train.jsonl` (schema: {question, context, answer, citations})
- MÃ´ hÃ¬nh & chá»‰ má»¥c:
  - `models/embeddings/legal-multilingual-e5-small-finetuned/` (bi-encoder)
  - `models/retrieval/faiss_index.bin`, `models/retrieval/metadata.json`, `models/retrieval/model_info.json`
  - (TÃ¹y chá»n) `models/retrieval/bm25_index.pkl` cho hybrid
- MÃ£ nguá»“n & cáº¥u hÃ¬nh:
  - `src/datasets/retrieval_prepare.py`, `src/datasets/qa_prepare.py`
  - `src/retrieval/train_biencoder.py`, `scripts/eval_retrieval.py`, `scripts/eval_qa.py`
  - `src/rag/generator/{gemini.py,local.py}`, `src/rag/generator/train_lora.py`
  - `config/retrieval.yaml`, `config/generator.yaml`
- TÃ i liá»‡u:
  - `docs/EXPERIMENTS.md` (nháº­t kÃ½ thÃ­ nghiá»‡m), cáº­p nháº­t `README.md`, `docs/Architecture.md`

### 3) Lá»™ trÃ¬nh & Má»‘c thá»i gian (Æ°á»›c lÆ°á»£ng)
- Tuáº§n 1: Chuáº©n hÃ³a dá»¯ liá»‡u retriever; dá»±ng `retrieval_train.jsonl`; baseline Ä‘Ã¡nh giÃ¡.
- Tuáº§n 2: Fine-tune bi-encoder (mE5-small); build FAISS; Ä‘Ã¡nh giÃ¡; triá»ƒn khai hybrid.
- Tuáº§n 3: TÃ­ch há»£p reranker; tá»‘i Æ°u tham sá»‘ Î± (hybrid) vÃ  topK; viáº¿t script Ä‘Ã¡nh giÃ¡.
- Tuáº§n 4: Chuáº©n hÃ³a QA dataset; thiáº¿t láº­p LoRA/QLoRA (local 3B hoáº·c Colab 8B); tÃ¡ch interface generator; cáº­p nháº­t prompt/Ä‘á»‹nh dáº¡ng.
- Tuáº§n 5: E2E test API; tá»‘i Æ°u hiá»‡u nÄƒng; viáº¿t tÃ i liá»‡u; chá»‘t nghiá»‡m thu.

### 4) CÃ´ng viá»‡c chi tiáº¿t (checklist thá»±c thi)

#### 4.1 Datasets â€“ Retriever
- [ ] Táº£i/Ä‘áº·t VNLAWQC, VNSynLawQC, ViRHE4QA vÃ o `data/raw/`
- [ ] Viáº¿t `src/datasets/retrieval_prepare.py`:
  - [ ] Chuáº©n hÃ³a schema; Ã¡nh xáº¡ passageâ†’chunk_id dá»±a trÃªn `metadata.json`
  - [ ] Sinh hard negatives (BM25/dense mining) vÃ  (tÃ¹y chá»n) synthetic queries
  - [ ] Xuáº¥t `data/processed/retrieval_train.jsonl`
- [ ] Baseline retriever hiá»‡n táº¡i: Ä‘o Recall@{1,5,10}, nDCG@10 (lÆ°u vÃ o `docs/EXPERIMENTS.md`)

#### 4.2 Fine-tune Bi-encoder (Sentence-Transformers)
- [ ] Viáº¿t `src/retrieval/train_biencoder.py` (máº·c Ä‘á»‹nh `intfloat/multilingual-e5-small`):
  - [ ] Loss: MultipleNegativesRankingLoss; batch size 64 (gradient_accumulation náº¿u cáº§n)
  - [ ] Hard negatives tá»« file train; evaluation má»—i N steps trÃªn dev
  - [ ] Hyperparams: lr 2e-5, epochs 3â€“5, warmup 10%, max_len 512
  - [ ] Xuáº¥t model ra `models/embeddings/legal-multilingual-e5-small-finetuned/`
- [ ] Cáº­p nháº­t `models/retrieval/model_info.json` (model_name, dim, ntotal, uses_id_map)

#### 4.3 Láº­p chá»‰ má»¥c & Metadata
- [ ] Cáº­p nháº­t `src/retrieval/build_index.py` Ä‘á»ƒ load model má»›i, táº¡o embeddings, build FAISS (IP + L2 normalize)
- [ ] Giá»¯ `ids = chunk_id` Ä‘á»ƒ Ä‘á»“ng bá»™ vá»›i content store; cáº­p nháº­t `metadata.json` gá»n nháº¹ (preview â‰¤ 200 char)
- [ ] LÆ°u `faiss_index.bin`, `metadata.json`, `model_info.json` vÃ o `models/retrieval/`
- [ ] Viáº¿t script kiá»ƒm chá»©ng tÃ­nh toÃ n váº¹n: sá»‘ vectors, Ä‘á»‘i chiáº¿u idâ†”metadata

#### 4.4 Hybrid BM25 + Dense
- [ ] XÃ¢y BM25 offline (`rank_bm25`) â†’ `bm25_index.pkl` (náº¿u lá»›n, cÃ¢n nháº¯c chá»‰ build cho title/heading)
- [ ] Sá»­a `src/retrieval/service.py`:
  - [ ] ThÃªm cháº¿ Ä‘á»™ hybrid: Ä‘iá»ƒm = Î±Â·dense + (1-Î±)Â·bm25 (ENV/config)
  - [ ] Tham sá»‘: `alpha`, `bm25_top_k`, `dense_top_k`, `final_top_k`
- [ ] Thá»­ nghiá»‡m grid Î±âˆˆ{0.2,0.4,0.6,0.8} trÃªn dev; ghi káº¿t quáº£

#### 4.5 Reranker (tuá»³ chá»n, báº­t qua cáº¥u hÃ¬nh)
- [ ] TÃ­ch há»£p `BAAI/bge-reranker-v2-m3` (CPU Ä‘Æ°á»£c): re-rank top-50 â†’ top-5
- [ ] Tham sá»‘: `reranker_on`, `reranker_model`, `reranker_top_k`
- [ ] ÄÃ¡nh giÃ¡ tÃ¡c Ä‘á»™ng tá»‘c Ä‘á»™ vs. cháº¥t lÆ°á»£ng; khuyáº¿n nghá»‹ báº­t khi cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao

#### 4.6 ÄÃ¡nh giÃ¡ Retriever
- [ ] Viáº¿t `scripts/eval_retrieval.py`:
  - [ ] Input: ground-truth pairs (queryâ†’gold chunk_id)
  - [ ] Metrics: Recall@k, MRR@k, nDCG@k; sinh báº£ng so sÃ¡nh baseline vs. tuned/hybrid/rerank
- [ ] LÆ°u káº¿t quáº£ (JSON + báº£ng Markdown) vÃ o `docs/EXPERIMENTS.md`

#### 4.7 Datasets â€“ QA Generator
- [ ] Viáº¿t `src/datasets/qa_prepare.py`:
  - [ ] Nguá»“n: VLQA, ViBidLQA, (tÃ¹y chá»n) ViRHE4QA cho extractive/abstractive
  - [ ] Chuáº©n hÃ³a: {question, context (passages+citation ids), answer, citations}
  - [ ] Lá»c cháº¥t lÆ°á»£ng, bá» duplicate, cÃ¢n báº±ng Ä‘á»™ dÃ i

#### 4.8 Generator â€“ LoRA/QLoRA
- [ ] Viáº¿t `src/rag/generator/train_lora.py` (HuggingFace + PEFT):
  - [ ] Local (4GB): LLaMA 3 3B / Qwen 2.5B + LoRA (r=8/16, Î±=16/32, target_modules=proj)
  - [ ] Colab T4 (12GB): 7Bâ€“8B + QLoRA (nf4/4bit, gradient_checkpointing, paged optim)
  - [ ] Early stopping, eval per epoch, save adapter â†’ `models/generator/*-lora/`
- [ ] Viáº¿t `src/rag/generator/local.py` Ä‘á»ƒ load base + adapter, sinh Ä‘Ã¡p Ã¡n tá»« context
- [ ] (Giá»¯ hiá»‡n tráº¡ng) `src/rag/generator/gemini.py` dÃ¹ng Gemini API Ä‘á»ƒ inference

#### 4.9 Chuáº©n hÃ³a Interface Generator & Prompt
- [ ] TÃ¡ch interface: `src/rag/generator/{gemini.py,local.py}` vá»›i cÃ¹ng hÃ m `generate(question, context, **kw)`
- [ ] Chá»n generator qua ENV/config (`RAG_GENERATOR=gemini|local`)
- [ ] Cáº­p nháº­t prompt trong `GeminiRAG`:
  - [ ] DÃ²ng Ä‘áº§u lÃ  tÃªn luáº­t phÃ¹ há»£p vá»›i nguá»“n Ä‘Æ°á»£c trÃ­ch
  - [ ] TrÃ¬nh bÃ y gáº¡ch Ä‘áº§u dÃ²ng; nhÃ³m trÃ­ch dáº«n theo Luáº­t vÃ  ghi Äiá»u/Khoáº£n/Äiá»ƒm
  - [ ] Náº¿u thiáº¿u thÃ´ng tin thÃ¬ nÃªu rÃµ Ä‘iá»u/khoáº£n cáº§n tham kháº£o thÃªm

#### 4.10 API, CLI & Cáº¥u hÃ¬nh
- [ ] Má»Ÿ rá»™ng `/ask`: tham sá»‘ `top_k`, `alpha`, `reranker_on`
- [ ] Äá»c config tá»« `config/retrieval.yaml`, `config/generator.yaml` (Æ°u tiÃªn ENV override)
- [ ] Logging chi tiáº¿t: thá»i gian retrieval/ rerank/ generation; kÃ­ch thÆ°á»›c context

#### 4.11 TÃ i liá»‡u & VÃ­ dá»¥ cháº¡y (Windows + conda)
- [ ] Cáº­p nháº­t `README.md` vÃ  `docs/Architecture.md` vá» RAG má»›i
- [ ] ThÃªm `docs/EXPERIMENTS.md` (mÃ´ táº£ version, siÃªu tham sá»‘, metric)
- [ ] HÆ°á»›ng dáº«n cháº¡y:
  - [ ] PowerShell:
    - `conda activate LegalAdvisor`
    - `python -m src.retrieval.build_index`
    - `python -m src.app.api --host 0.0.0.0 --port 8000`

### 5) TiÃªu chÃ­ nghiá»‡m thu
- Retriever tuned (khÃ´ng rerank): Recall@5 â‰¥ 0.75, nDCG@10 â‰¥ 0.75 trÃªn dev
- Vá»›i hybrid+rerank: tÄƒng â‰¥ +0.05 nDCG@10 so vá»›i dense-only, P50 latency â‰¤ 4.5s
- CÃ¢u tráº£ lá»i chuáº©n hÃ³a trÃ­ch dáº«n Ä‘Ãºng Luáº­t/Äiá»u/Khoáº£n/Äiá»ƒm; Ä‘á»‹nh dáº¡ng dá»… Ä‘á»c
- TÃ i liá»‡u Ä‘áº§y Ä‘á»§; lá»‡nh cháº¡y Windows/conda hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh

### 6) Rá»§i ro & Giáº£m thiá»ƒu
- `bitsandbytes`/QLoRA trÃªn Windows kÃ©m á»•n Ä‘á»‹nh â†’ cháº¡y LoRA local 3B hoáº·c QLoRA trÃªn Colab
- Sai lá»‡ch mapping queryâ†’chunk_id giá»¯a datasets vÃ  `metadata.json` â†’ viáº¿t validator hai chiá»u
- Reranker CPU cháº­m â†’ báº­t tuá»³ tÃ¬nh huá»‘ng; giáº£m `reranker_top_k`; cache káº¿t quáº£ truy váº¥n láº·p láº¡i
- Dung lÆ°á»£ng index lá»›n â†’ rÃºt gá»n preview, nÃ©n BM25 index, batch encode há»£p lÃ½

### 7) Theo dÃµi tiáº¿n Ä‘á»™ (macro)
- [ ] Datasets retriever chuáº©n hÃ³a xong
- [ ] Bi-encoder fine-tune xong vÃ  vÆ°á»£t baseline
- [ ] FAISS + Hybrid + (Rerank tuá»³ chá»n) hoÃ n thiá»‡n, cÃ³ bÃ¡o cÃ¡o metric
- [ ] QA dataset chuáº©n hÃ³a + LoRA/QLoRA huáº¥n luyá»‡n xong
- [ ] TÃ¡ch interface generator + cáº¥u hÃ¬nh ENV hoáº¡t Ä‘á»™ng
- [ ] API/Docs/E2E test hoÃ n chá»‰nh
