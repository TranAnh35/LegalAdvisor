#!/usr/bin/env python3
"""
Launcher Ä‘Æ¡n giáº£n cho LegalAdvisor
"""

import sys
import os
import signal
import subprocess
import time
from pathlib import Path
from dotenv import load_dotenv
import json

def check_requirements():
    """Kiá»ƒm tra cÃ¡c yÃªu cáº§u cÆ¡ báº£n"""
    print("ğŸ” Kiá»ƒm tra yÃªu cáº§u há»‡ thá»‘ng...")

    # Kiá»ƒm tra Python version
    if sys.version_info < (3, 8):
        print(f"âŒ Cáº§n Python >= 3.8, hiá»‡n táº¡i: {sys.version}")
        return False

    # Kiá»ƒm tra GPU vÃ  hiá»ƒn thá»‹ thÃ´ng tin
    print("ğŸ”¥ Kiá»ƒm tra GPU support...")
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        if gpu_available:
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            print(f"âœ… GPU available: {gpu_name} ({gpu_count} GPU(s))")
            print("   ğŸš€ LegalAdvisor will use GPU acceleration for better performance!")
        else:
            print("âš ï¸  GPU not available - using CPU mode")
            print("   ğŸ’¡ Run 'python check_gpu.py' for GPU setup instructions")
    except ImportError:
        print("âš ï¸  PyTorch not found - GPU check skipped")

    # Kiá»ƒm tra thÆ° má»¥c cáº§n thiáº¿t
    required_dirs = ["data/processed", "models"]
    for dir_path in required_dirs:
        if not Path(dir_path).exists():
            print(f"âš ï¸ Thiáº¿u thÆ° má»¥c: {dir_path}")
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            print(f"âœ… ÄÃ£ táº¡o thÆ° má»¥c: {dir_path}")

    # Kiá»ƒm tra dataset
    dataset_files = [
        # Chuáº©n: dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ á»Ÿ SQLite/Parquet
        "data/processed/smart_chunks_stable.db",
        "data/processed/smart_chunks_stable.parquet",
        "data/raw/ViQuAD/train.json"
    ]

    missing_datasets = []
    for file_path in dataset_files:
        if not Path(file_path).exists():
            missing_datasets.append(file_path)

    if missing_datasets:
        print("â„¹ï¸  Má»™t sá»‘ datasets chÆ°a cÃ³ (khÃ´ng báº¯t buá»™c Ä‘á»ƒ cháº¡y launcher):")
        for missing in missing_datasets:
            print(f"   - {missing}")
        print("   â†’ CÃ³ thá»ƒ táº¡o riÃªng khi cáº§n.")

    # Kiá»ƒm tra mÃ´ hÃ¬nh retrieval Ä‘Ã£ sáºµn sÃ ng chÆ°a
    retrieval_dir = Path("models/retrieval")
    index_path = retrieval_dir / "faiss_index.bin"
    meta_path = retrieval_dir / "metadata.json"
    info_path = retrieval_dir / "model_info.json"
    if not retrieval_dir.exists() or not index_path.exists() or not meta_path.exists() or not info_path.exists():
        print("âš ï¸  Thiáº¿u mÃ´ hÃ¬nh retrieval (FAISS/metadata/model_info).")
        print("   ğŸ’¡ Vui lÃ²ng cháº¡y riÃªng bÆ°á»›c build index trÆ°á»›c khi launch:")
        print("      conda activate LegalAdvisor")
        print("      python src/retrieval/build_index.py")
    else:
        try:
            with open(info_path, 'r', encoding='utf-8') as f:
                mi = json.load(f)
            model_name = mi.get('model_name')
            dim = mi.get('embedding_dim')
            metric = mi.get('metric_type', 'ip')
            pooling = mi.get('pooling', 'unknown')
            print(f"ğŸ”§ Retrieval model: {model_name} | dim={dim} | metric={metric} | pooling={pooling}")
        except Exception:
            print("â„¹ï¸  KhÃ´ng Ä‘á»c Ä‘Æ°á»£c model_info.json Ä‘á»ƒ hiá»ƒn thá»‹ thÃ´ng tin mÃ´ hÃ¬nh.")

    print("âœ… Kiá»ƒm tra hoÃ n thÃ nh!")
    return True

# Global variables
api_process = None
ui_process = None

def start_api_server(use_gpu=False):
    """Khá»Ÿi Ä‘á»™ng API server vá»›i subprocess
    
    Args:
        use_gpu (bool): CÃ³ sá»­ dá»¥ng GPU hay khÃ´ng
    """
    global api_process

    try:
        print("ğŸš€ Khá»Ÿi Ä‘á»™ng API server...")
        cmd = [
            sys.executable,
            "-m", "src.app.api",
            "--host", "0.0.0.0",
            "--port", "8000"
        ]
        
        # ThÃªm tÃ¹y chá»n --use-gpu náº¿u Ä‘Æ°á»£c yÃªu cáº§u
        if use_gpu:
            cmd.append("--use-gpu")
            print("   ğŸš€ Cháº¿ Ä‘á»™ GPU Ä‘Ã£ Ä‘Æ°á»£c kÃ­ch hoáº¡t")
        else:
            print("   âš¡ Cháº¿ Ä‘á»™ CPU")

        # Náº¡p .env Ä‘á»ƒ láº¥y GOOGLE_API_KEY náº¿u cÃ³
        try:
            load_dotenv()
        except Exception:
            pass

        # Báº¯t buá»™c sá»­ dá»¥ng Gemini: yÃªu cáº§u GOOGLE_API_KEY vÃ  Ä‘áº·t RAG_ENGINE=gemini
        env = os.environ.copy()
        if not env.get("GOOGLE_API_KEY"):
            raise RuntimeError("GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p. Vui lÃ²ng táº¡o .env vÃ  Ä‘áº·t GOOGLE_API_KEY.")
        env["RAG_ENGINE"] = "gemini"
        # Truyá»n hint sá»­ dá»¥ng GPU cho cÃ¡c tiáº¿n trÃ¬nh con
        env["LEGALADVISOR_USE_GPU"] = "1" if use_gpu else "0"
        api_process = subprocess.Popen(cmd, env=env)
        print("âœ… API server Ä‘Ã£ khá»Ÿi Ä‘á»™ng (PID: {})".format(api_process.pid))

    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi Ä‘á»™ng API: {e}")
        return False

    return True

def start_ui_server():
    """Khá»Ÿi Ä‘á»™ng UI server báº±ng streamlit run Ä‘á»ƒ trÃ¡nh cáº£nh bÃ¡o bare mode"""
    global ui_process

    try:
        print("ğŸš€ Khá»Ÿi Ä‘á»™ng UI server (streamlit run)...")
        cmd = [
            sys.executable, "-m", "streamlit", "run",
            "src/app/ui.py",
            "--server.address", "localhost",
            "--server.port", "8501",
            "--browser.gatherUsageStats", "false",
            "--server.headless", "true"
        ]

        env = os.environ.copy()
        ui_process = subprocess.Popen(cmd, env=env)
        print("âœ… UI server Ä‘Ã£ khá»Ÿi Ä‘á»™ng (PID: {})".format(ui_process.pid))

    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi Ä‘á»™ng UI: {e}")
        return False

    return True

def stop_servers():
    """Dá»«ng táº¥t cáº£ servers"""
    global api_process, ui_process

    print("\nğŸ”„ Äang dá»«ng servers...")

    # Dá»«ng API process
    if api_process:
        try:
            api_process.terminate()
            api_process.wait(timeout=5)
            print("âœ… API server stopped")
        except subprocess.TimeoutExpired:
            api_process.kill()
            print("âœ… API server force killed")
        except Exception as e:
            print(f"âš ï¸ Lá»—i dá»«ng API: {e}")

    # Dá»«ng UI process
    if ui_process:
        try:
            ui_process.terminate()
            ui_process.wait(timeout=5)
            print("âœ… UI server stopped")
        except subprocess.TimeoutExpired:
            ui_process.kill()
            print("âœ… UI server force killed")
        except Exception as e:
            print(f"âš ï¸ Lá»—i dá»«ng UI: {e}")

def signal_handler(signum, frame):
    """Handle shutdown signals"""
    print(f"\nğŸ›‘ Nháº­n tÃ­n hiá»‡u {signum}, Ä‘ang táº¯t há»‡ thá»‘ng...")
    stop_servers()
    print("ğŸ‘‹ Cáº£m Æ¡n Ä‘Ã£ sá»­ dá»¥ng LegalAdvisor!")
    sys.exit(0)

def main():
    """HÃ m chÃ­nh"""
    # Náº¡p .env sá»›m Ä‘á»ƒ cÃ¡c ENV nhÆ° GOOGLE_API_KEY/LEGALADVISOR_* cÃ³ hiá»‡u lá»±c
    try:
        load_dotenv()
    except Exception:
        pass
    print("\n" + "="*50)
    print("   ğŸ›ï¸  LegalAdvisor - Há»‡ thá»‘ng há»— trá»£ phÃ¡p lÃ½")
    print("   ğŸš€ PhiÃªn báº£n: 2.0 (Gemini Integration)")
    print("="*50 + "\n")
    
    # Kiá»ƒm tra xem cÃ³ GPU khÃ´ng
    use_gpu = False
    try:
        import torch
        if torch.cuda.is_available():
            use_gpu = True
            print("âœ… ÄÃ£ phÃ¡t hiá»‡n GPU, sáº½ sá»­ dá»¥ng GPU Ä‘á»ƒ tÄƒng tá»‘c xá»­ lÃ½")
        else:
            print("â„¹ï¸  KhÃ´ng phÃ¡t hiá»‡n GPU, sáº½ sá»­ dá»¥ng CPU")
    except ImportError:
        print("âš ï¸  KhÃ´ng thá»ƒ kiá»ƒm tra GPU do chÆ°a cÃ i Ä‘áº·t PyTorch")
    print("ğŸ¤– Sá»­ dá»¥ng Google Gemini cho text generation (báº¯t buá»™c)")

    # Setup signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Kiá»ƒm tra yÃªu cáº§u
    if not check_requirements():
        sys.exit(1)

    print("\nğŸš€ Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng...")

    try:
        # Khá»Ÿi Ä‘á»™ng API server
        if not start_api_server(use_gpu=use_gpu):
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng API server")
            sys.exit(1)

        # Äá»£i API khá»Ÿi Ä‘á»™ng vá»›i vÃ²ng retry (tá»‘i Ä‘a 60 giÃ¢y)
        print("â³ Äá»£i API server khá»Ÿi Ä‘á»™ng hoÃ n toÃ n (tá»‘i Ä‘a 60s)...")
        import requests
        max_wait_seconds = 60
        start_time_wait = time.time()
        attempt = 0
        while True:
            attempt += 1
            # Náº¿u process API Ä‘Ã£ thoÃ¡t, thÃ´ng bÃ¡o lá»—i sá»›m
            if api_process and api_process.poll() is not None:
                print("âŒ API server Ä‘Ã£ dá»«ng trong quÃ¡ trÃ¬nh khá»Ÿi Ä‘á»™ng. Vui lÃ²ng xem logs hiá»ƒn thá»‹ tá»« API.")
                print("ğŸ’¡ Gá»£i Ã½: kiá»ƒm tra GOOGLE_API_KEY, thÆ° má»¥c models/retrieval vÃ  káº¿t ná»‘i internet.")
                print("   â†’ Náº¿u cáº§n xÃ¢y láº¡i index: python src/retrieval/build_index.py")
                sys.exit(1)

            try:
                response = requests.get("http://localhost:8000/health", timeout=3)
                if response.status_code == 200:
                    print("âœ… API server Ä‘Ã£ sáºµn sÃ ng!")
                    break
                else:
                    print(f"âš ï¸ /health tráº£ vá»: {response.status_code} (attempt {attempt})")
            except Exception:
                # ChÆ°a sáºµn sÃ ng, tiáº¿p tá»¥c Ä‘á»£i
                pass

            elapsed = time.time() - start_time_wait
            if elapsed >= max_wait_seconds:
                print("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i API trong 60 giÃ¢y.")
                print("ğŸ’¡ Gá»£i Ã½: kiá»ƒm tra GOOGLE_API_KEY, thÆ° má»¥c models/retrieval vÃ  logs cá»§a API.")
                print("   â†’ Náº¿u thiáº¿u index: python src/retrieval/build_index.py")
                break
            time.sleep(1)

        # Khá»Ÿi Ä‘á»™ng UI server
        if not start_ui_server():
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng UI server")
            stop_servers()
            sys.exit(1)

        print("\nğŸ‰ Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!")
        print("=" * 50)
        print("ğŸ“± Truy cáº­p:")
        print("   - Web UI: http://localhost:8501")
        print("   - API: http://localhost:8000")
        print("   - API Docs: http://localhost:8000/docs")
        print("\nğŸ›‘ Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng há»‡ thá»‘ng")
        print("=" * 50)

        # Giá»¯ main thread cháº¡y vÃ  monitor processes
        while True:
            # Kiá»ƒm tra xem processes cÃ²n cháº¡y khÃ´ng
            if api_process and api_process.poll() is not None:
                print("âš ï¸ API server Ä‘Ã£ dá»«ng báº¥t ngá»")
                break
            if ui_process and ui_process.poll() is not None:
                print("âš ï¸ UI server Ä‘Ã£ dá»«ng báº¥t ngá»")
                break

            time.sleep(1)

    except KeyboardInterrupt:
        print("\nğŸ›‘ Äang dá»«ng há»‡ thá»‘ng...")
        stop_servers()
        print("ğŸ‘‹ Cáº£m Æ¡n Ä‘Ã£ sá»­ dá»¥ng LegalAdvisor!")

    except Exception as e:
        print(f"\nâŒ Lá»—i: {e}")
        stop_servers()
        print("ğŸ‘‹ Cáº£m Æ¡n Ä‘Ã£ sá»­ dá»¥ng LegalAdvisor!")

if __name__ == "__main__":
    main()
