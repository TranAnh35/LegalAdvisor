#!/usr/bin/env python3
"""
Launcher Ä‘Æ¡n giáº£n cho LegalAdvisor
"""

import sys
import os
import signal
import subprocess
import time
from pathlib import Path
from dotenv import load_dotenv
import json

def check_requirements():
    """Kiá»ƒm tra cÃ¡c yÃªu cáº§u cÆ¡ báº£n"""
    print("ğŸ” Kiá»ƒm tra yÃªu cáº§u há»‡ thá»‘ng...")

    # Kiá»ƒm tra GPU vÃ  hiá»ƒn thá»‹ thÃ´ng tin
    print("ğŸ”¥ Kiá»ƒm tra GPU support...")
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        if gpu_available:
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            print(f"âœ… GPU available: {gpu_name} ({gpu_count} GPU(s))")
            print("   ğŸš€ LegalAdvisor will use GPU acceleration for better performance!")
        else:
            print("âš ï¸  GPU not available - using CPU mode")
            print("   ğŸ’¡ Run 'python check_gpu.py' for GPU setup instructions")
    except ImportError:
        print("âš ï¸  PyTorch not found - GPU check skipped")

    # Kiá»ƒm tra thÆ° má»¥c cáº§n thiáº¿t
    required_dirs = ["data/processed", "models"]
    for dir_path in required_dirs:
        if not Path(dir_path).exists():
            print(f"âš ï¸ Thiáº¿u thÆ° má»¥c: {dir_path}")
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            print(f"âœ… ÄÃ£ táº¡o thÆ° má»¥c: {dir_path}")

    # Kiá»ƒm tra dataset (Æ°u tiÃªn pipeline má»›i Zalo-Legal)
    dataset_files = [
        # Dá»¯ liá»‡u Ä‘Ã£ tiá»n xá»­ lÃ½ cho pipeline má»›i
        "data/processed/zalo-legal/chunks_schema.jsonl"
    ]

    missing_datasets = []
    for file_path in dataset_files:
        if not Path(file_path).exists():
            missing_datasets.append(file_path)

    if missing_datasets:
        print("â„¹ï¸  ChÆ°a tÃ¬m tháº¥y dá»¯ liá»‡u Ä‘Ã£ tiá»n xá»­ lÃ½ cho pipeline Zalo-Legal:")
        for missing in missing_datasets:
            print(f"   - {missing}")
        print("   â†’ HÃ£y cháº¡y: python scripts/zalo_legal_preprocess.py (sau khi Ä‘Ã£ download)")

    # Kiá»ƒm tra mÃ´ hÃ¬nh retrieval Ä‘Ã£ sáºµn sÃ ng chÆ°a (há»— trá»£ index_v2, index vÃ  cáº¥u trÃºc cÅ©)
    retrieval_dir = Path("models/retrieval")
    index_candidates = [
        ("index_v2", retrieval_dir / "index_v2"),
        ("index", retrieval_dir / "index"),
    ]
    selected_index = None
    for label, base_dir in index_candidates:
        idx_path = base_dir / "chunks_index.faiss"
        info_path = base_dir / "model_info.json"
        meta_path = base_dir / "metadata.json"
        if base_dir.exists() and idx_path.exists() and info_path.exists():
            selected_index = {
                "label": label,
                "base_dir": base_dir,
                "index_path": idx_path,
                "info_path": info_path,
                "meta_path": meta_path,
            }
            break

    # Cáº¥u trÃºc cÅ© (1 file index + 1 model_info)
    old_index_path = retrieval_dir / "faiss_index.bin"
    old_info_path = retrieval_dir / "model_info.json"
    old_meta_path = retrieval_dir / "metadata.json"

    has_new = selected_index is not None
    has_old = retrieval_dir.exists() and old_index_path.exists() and old_info_path.exists()

    if not has_new and not has_old:
        print("âš ï¸  Thiáº¿u mÃ´ hÃ¬nh retrieval (FAISS/metadata/model_info).")
        print("   ğŸ’¡ Vui lÃ²ng cháº¡y riÃªng bÆ°á»›c build index trÆ°á»›c khi launch:")
        print("      conda activate LegalAdvisor")
        print("      python src/retrieval/build_index.py")
    else:
        # Æ¯u tiÃªn Ä‘á»c model_info theo cáº¥u trÃºc má»›i
        info_path = selected_index["info_path"] if has_new else old_info_path
        try:
            with open(info_path, 'r', encoding='utf-8') as f:
                mi = json.load(f)
            model_name = mi.get('model_name')
            dim = mi.get('embedding_dim')
            metric = mi.get('metric_type', 'ip')
            pooling = mi.get('pooling', 'unknown')
            location = f"{selected_index['label']}/" if has_new else "legacy/"
            print(f"ğŸ”§ Retrieval model: {model_name} | dim={dim} | metric={metric} | pooling={pooling} ({location})")
        except Exception:
            print("â„¹ï¸  KhÃ´ng Ä‘á»c Ä‘Æ°á»£c model_info.json Ä‘á»ƒ hiá»ƒn thá»‹ thÃ´ng tin mÃ´ hÃ¬nh.")
        # Cáº£nh bÃ¡o nháº¹ náº¿u thiáº¿u metadata (chá»‰ áº£nh hÆ°á»Ÿng endpoint /stats)
        if has_new:
            meta_exists = selected_index["meta_path"].exists()
        else:
            meta_exists = old_meta_path.exists()
        if not meta_exists:
            print("â„¹ï¸  ChÆ°a tÃ¬m tháº¥y metadata.json (chá»‰ áº£nh hÆ°á»Ÿng thá»‘ng kÃª /stats).")

    print("âœ… Kiá»ƒm tra hoÃ n thÃ nh!")
    return True

# Global variables
api_process = None
ui_process = None

def start_api_server(use_gpu=False):
    """Khá»Ÿi Ä‘á»™ng API server vá»›i subprocess
    
    Args:
        use_gpu (bool): CÃ³ sá»­ dá»¥ng GPU hay khÃ´ng
    """
    global api_process

    try:
        print("ğŸš€ Khá»Ÿi Ä‘á»™ng API server...")
        cmd = [
            sys.executable,
            "-m", "src.app.api",
            "--host", "0.0.0.0",
            "--port", "8000"
        ]
        
        # ThÃªm tÃ¹y chá»n --use-gpu náº¿u Ä‘Æ°á»£c yÃªu cáº§u
        if use_gpu:
            cmd.append("--use-gpu")
            print("   ğŸš€ Cháº¿ Ä‘á»™ GPU Ä‘Ã£ Ä‘Æ°á»£c kÃ­ch hoáº¡t")
        else:
            print("   âš¡ Cháº¿ Ä‘á»™ CPU")

        # Náº¡p .env Ä‘á»ƒ láº¥y GOOGLE_API_KEY náº¿u cÃ³
        try:
            load_dotenv()
        except Exception:
            pass

        # Báº¯t buá»™c sá»­ dá»¥ng Gemini: yÃªu cáº§u GOOGLE_API_KEY vÃ  Ä‘áº·t RAG_ENGINE=gemini
        env = os.environ.copy()
        if not env.get("GOOGLE_API_KEY"):
            raise RuntimeError("GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p. Vui lÃ²ng táº¡o .env vÃ  Ä‘áº·t GOOGLE_API_KEY.")
        env["RAG_ENGINE"] = "gemini"
        # Truyá»n hint sá»­ dá»¥ng GPU cho cÃ¡c tiáº¿n trÃ¬nh con
        env["LEGALADVISOR_USE_GPU"] = "1" if use_gpu else "0"
        api_process = subprocess.Popen(cmd, env=env)
        print("âœ… API server Ä‘Ã£ khá»Ÿi Ä‘á»™ng (PID: {})".format(api_process.pid))

    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi Ä‘á»™ng API: {e}")
        return False

    return True

def start_ui_server():
    """Khá»Ÿi Ä‘á»™ng UI server báº±ng streamlit run Ä‘á»ƒ trÃ¡nh cáº£nh bÃ¡o bare mode"""
    global ui_process

    try:
        print("ğŸš€ Khá»Ÿi Ä‘á»™ng UI server (streamlit run)...")
        cmd = [
            sys.executable, "-m", "streamlit", "run",
            "src/app/ui.py",
            "--server.address", "localhost",
            "--server.port", "8501",
            "--browser.gatherUsageStats", "false",
            "--server.headless", "true"
        ]

        env = os.environ.copy()
        ui_process = subprocess.Popen(cmd, env=env)
        print("âœ… UI server Ä‘Ã£ khá»Ÿi Ä‘á»™ng (PID: {})".format(ui_process.pid))

    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi Ä‘á»™ng UI: {e}")
        return False

    return True

def stop_servers():
    """Dá»«ng táº¥t cáº£ servers"""
    global api_process, ui_process

    print("\nğŸ”„ Äang dá»«ng servers...")

    # Dá»«ng API process
    if api_process:
        try:
            api_process.terminate()
            api_process.wait(timeout=5)
            print("âœ… API server stopped")
        except subprocess.TimeoutExpired:
            api_process.kill()
            print("âœ… API server force killed")
        except Exception as e:
            print(f"âš ï¸ Lá»—i dá»«ng API: {e}")

    # Dá»«ng UI process
    if ui_process:
        try:
            ui_process.terminate()
            ui_process.wait(timeout=5)
            print("âœ… UI server stopped")
        except subprocess.TimeoutExpired:
            ui_process.kill()
            print("âœ… UI server force killed")
        except Exception as e:
            print(f"âš ï¸ Lá»—i dá»«ng UI: {e}")

def signal_handler(signum, frame):
    """Handle shutdown signals"""
    print(f"\nğŸ›‘ Nháº­n tÃ­n hiá»‡u {signum}, Ä‘ang táº¯t há»‡ thá»‘ng...")
    stop_servers()
    print("ğŸ‘‹ Cáº£m Æ¡n Ä‘Ã£ sá»­ dá»¥ng LegalAdvisor!")
    sys.exit(0)

def main():
    """HÃ m chÃ­nh"""
    # Náº¡p .env sá»›m Ä‘á»ƒ cÃ¡c ENV nhÆ° GOOGLE_API_KEY/LEGALADVISOR_* cÃ³ hiá»‡u lá»±c
    try:
        load_dotenv()
    except Exception:
        pass
    print("\n" + "="*50)
    print("   ğŸ›ï¸  LegalAdvisor - Há»‡ thá»‘ng há»— trá»£ phÃ¡p lÃ½")
    print("="*50 + "\n")
    
    # Kiá»ƒm tra xem cÃ³ cá» Ã©p buá»™c sá»­ dá»¥ng CPU hay khÃ´ng (env override)
    use_gpu = False
    env_override = os.environ.get("LEGALADVISOR_USE_GPU")
    if env_override is not None:
        # Accept common truthy/falsy values
        if env_override.lower() in ("1", "true", "yes", "on"):
            use_gpu = True
            print("âœ… LEGALADVISOR_USE_GPU env override: báº­t GPU")
        else:
            use_gpu = False
            print("âœ… LEGALADVISOR_USE_GPU env override: táº¯t GPU (sá»­ dá»¥ng CPU)")
    else:
        try:
            import torch
            if torch.cuda.is_available():
                use_gpu = True
                print("âœ… ÄÃ£ phÃ¡t hiá»‡n GPU, sáº½ sá»­ dá»¥ng GPU Ä‘á»ƒ tÄƒng tá»‘c xá»­ lÃ½")
            else:
                print("â„¹ï¸  KhÃ´ng phÃ¡t hiá»‡n GPU, sáº½ sá»­ dá»¥ng CPU")
        except ImportError:
            print("âš ï¸  KhÃ´ng thá»ƒ kiá»ƒm tra GPU do chÆ°a cÃ i Ä‘áº·t PyTorch")
    print("ğŸ¤– Sá»­ dá»¥ng Google Gemini cho text generation (báº¯t buá»™c)")

    # Setup signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Kiá»ƒm tra yÃªu cáº§u
    if not check_requirements():
        sys.exit(1)

    print("\nğŸš€ Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng...")

    try:
        # Khá»Ÿi Ä‘á»™ng API server
        if not start_api_server(use_gpu=use_gpu):
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng API server")
            sys.exit(1)

        # Äá»£i API khá»Ÿi Ä‘á»™ng vá»›i vÃ²ng retry (tá»‘i Ä‘a 60 giÃ¢y)
        print("â³ Äá»£i API server khá»Ÿi Ä‘á»™ng hoÃ n toÃ n (tá»‘i Ä‘a 60s)...")
        import requests
        max_wait_seconds = 60
        start_time_wait = time.time()
        attempt = 0
        while True:
            attempt += 1
            # Náº¿u process API Ä‘Ã£ thoÃ¡t, thÃ´ng bÃ¡o lá»—i sá»›m
            if api_process and api_process.poll() is not None:
                print("âŒ API server Ä‘Ã£ dá»«ng trong quÃ¡ trÃ¬nh khá»Ÿi Ä‘á»™ng. Vui lÃ²ng xem logs hiá»ƒn thá»‹ tá»« API.")
                print("ğŸ’¡ Gá»£i Ã½: kiá»ƒm tra GOOGLE_API_KEY, thÆ° má»¥c models/retrieval vÃ  káº¿t ná»‘i internet.")
                print("   â†’ Náº¿u cáº§n xÃ¢y láº¡i index: python src/retrieval/build_index.py")
                sys.exit(1)

            try:
                response = requests.get("http://localhost:8000/health", timeout=3)
                if response.status_code == 200:
                    print("âœ… API server Ä‘Ã£ sáºµn sÃ ng!")
                    break
                else:
                    print(f"âš ï¸ /health tráº£ vá»: {response.status_code} (attempt {attempt})")
            except Exception:
                # ChÆ°a sáºµn sÃ ng, tiáº¿p tá»¥c Ä‘á»£i
                pass

            elapsed = time.time() - start_time_wait
            if elapsed >= max_wait_seconds:
                print("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i API trong 60 giÃ¢y.")
                print("ğŸ’¡ Gá»£i Ã½: kiá»ƒm tra GOOGLE_API_KEY, thÆ° má»¥c models/retrieval vÃ  logs cá»§a API.")
                print("   â†’ Náº¿u thiáº¿u index: python src/retrieval/build_index.py")
                break
            time.sleep(1)

        # Khá»Ÿi Ä‘á»™ng UI server
        if not start_ui_server():
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng UI server")
            stop_servers()
            sys.exit(1)

        print("\nğŸ‰ Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!")
        print("=" * 50)
        print("ğŸ“± Truy cáº­p:")
        print("   - Web UI: http://localhost:8501")
        print("   - API: http://localhost:8000")
        print("   - API Docs: http://localhost:8000/docs")
        print("\nğŸ›‘ Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng há»‡ thá»‘ng")
        print("=" * 50)

        # Giá»¯ main thread cháº¡y vÃ  monitor processes
        while True:
            # Kiá»ƒm tra xem processes cÃ²n cháº¡y khÃ´ng
            if api_process and api_process.poll() is not None:
                print("âš ï¸ API server Ä‘Ã£ dá»«ng báº¥t ngá»")
                break
            if ui_process and ui_process.poll() is not None:
                print("âš ï¸ UI server Ä‘Ã£ dá»«ng báº¥t ngá»")
                break

            time.sleep(1)

    except KeyboardInterrupt:
        print("\nğŸ›‘ Äang dá»«ng há»‡ thá»‘ng...")
        stop_servers()
        print("ğŸ‘‹ Cáº£m Æ¡n Ä‘Ã£ sá»­ dá»¥ng LegalAdvisor!")

    except Exception as e:
        print(f"\nâŒ Lá»—i: {e}")
        stop_servers()
        print("ğŸ‘‹ Cáº£m Æ¡n Ä‘Ã£ sá»­ dá»¥ng LegalAdvisor!")

if __name__ == "__main__":
    main()
