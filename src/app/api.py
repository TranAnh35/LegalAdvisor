#!/usr/bin/env python3
"""
FastAPI backend cho LegalAdvisor
"""

import sys
import os
import signal
sys.path.append('../..')

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import uvicorn
from pathlib import Path
import json
import time
import torch

# Import logger
try:
    from utils.logger import get_logger, log_performance, log_error
    logger = get_logger("legaladvisor.api")
except ImportError:
    # Fallback if utils not available
    import logging
    logger = logging.getLogger("legaladvisor.api")
    logger.setLevel(logging.INFO)

    def log_performance(operation, duration, metadata=None):
        logger.info(f"Performance: {operation} took {duration:.2f}s")

    def log_error(message):
        logger.error(message)

# Import RAG pipeline - Sá»­ dá»¥ng GeminiRAG
import sys
import os
import argparse
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# Parse command line arguments
parser = argparse.ArgumentParser(description='LegalAdvisor API Server')
parser.add_argument('--host', default='0.0.0.0', help='Host Ä‘á»ƒ cháº¡y server')
parser.add_argument('--port', type=int, default=8000, help='Port Ä‘á»ƒ cháº¡y server')
parser.add_argument('--use-gpu', action='store_true', help='Sá»­ dá»¥ng GPU náº¿u cÃ³ sáºµn')
args, unknown = parser.parse_known_args()

# Initialize RAG system: luÃ´n dÃ¹ng GeminiRAG (lazy init Ä‘á»ƒ tÄƒng tá»‘c khá»Ÿi Ä‘á»™ng)
rag_system = None

def _init_rag_background():
    global rag_system
    try:
        from rag.gemini_rag import GeminiRAG
        rag_system = GeminiRAG(use_gpu=args.use_gpu)
        print("ğŸ¤– ÄÃ£ khá»Ÿi táº¡o GeminiRAG thÃ nh cÃ´ng (lazy)!")
    except Exception as e:
        print(f"âŒ Lá»—i khi khá»Ÿi táº¡o GeminiRAG (lazy): {str(e)}")

import threading
threading.Thread(target=_init_rag_background, daemon=True).start()

# Khá»Ÿi táº¡o FastAPI
app = FastAPI(
    title="LegalAdvisor API",
    description="API cho há»‡ thá»‘ng há»i Ä‘Ã¡p phÃ¡p luáº­t tiáº¿ng Viá»‡t",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models
class QuestionRequest(BaseModel):
    question: str
    top_k: Optional[int] = 3

class AnswerResponse(BaseModel):
    question: str
    answer: str
    confidence: float
    sources: List[Dict[str, Any]]
    num_sources: int
    status: str

class HealthResponse(BaseModel):
    status: str
    message: str
    rag_loaded: bool

@app.get("/", tags=["General"])
async def root():
    """Trang chá»§ API"""
    return {
        "message": "Welcome to LegalAdvisor API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """Kiá»ƒm tra tráº¡ng thÃ¡i há»‡ thá»‘ng"""
    return HealthResponse(
        status="healthy" if rag_system else "degraded",
        message="LegalAdvisor API is running",
        rag_loaded=rag_system is not None
    )

@app.post("/ask", response_model=AnswerResponse, tags=["QA"])
async def ask_question(request: QuestionRequest):
    """Tráº£ lá»i cÃ¢u há»i phÃ¡p luáº­t"""

    logger.info(f"Received question: {request.question}")
    start_time = time.time()

    if not rag_system:
        log_error("RAG system not available")
        raise HTTPException(
            status_code=503,
            detail="RAG system is not available. Please check the system logs."
        )

    try:
        # Xá»­ lÃ½ cÃ¢u há»i
        # Sá»­ dá»¥ng GeminiRAG.ask Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i vÃ  nguá»“n
        result = rag_system.ask(request.question, top_k=request.top_k or 3)

        response_time = time.time() - start_time
        log_performance("api_request", response_time, {
            "question": request.question,
            "confidence": float(result.get('confidence', 0.0)),
            "num_sources": int(result.get('num_sources', 0))
        })

        # Táº¡o pháº£n há»“i chuáº©n hÃ³a, GeminiRAG hiá»‡n chÆ°a tráº£ vá» confidence -> máº·c Ä‘á»‹nh 0.0
        return AnswerResponse(
            question=result.get('question', request.question),
            answer=result.get('answer', ''),
            confidence=float(result.get('confidence', 0.0)),
            sources=result.get('sources', []),
            num_sources=int(result.get('num_sources', 0)),
            status=result.get('status', 'success')
        )

    except Exception as e:
        log_error(f"Error processing question '{request.question}': {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error processing question: {str(e)}"
        )

@app.get("/stats", tags=["Statistics"])
async def get_stats():
    """Thá»‘ng kÃª há»‡ thá»‘ng"""

    if not rag_system:
        return {"error": "RAG system not loaded"}

    try:
        # Load metadata Ä‘á»ƒ láº¥y thá»‘ng kÃª
        # XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n models/retrieval tá»« root dá»± Ã¡n hoáº·c tá»« biáº¿n mÃ´i trÆ°á»ng
        env_models_dir = os.getenv("LEGALADVISOR_MODELS_DIR")
        if env_models_dir:
            model_dir = Path(env_models_dir)
        else:
            current_dir = Path(__file__).resolve().parent  # src/app
            root_dir = current_dir.parent.parent  # -> root
            model_dir = root_dir / "models" / "retrieval"
        metadata_path = model_dir / "metadata.json"

        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            total_chunks = len(metadata)
            total_words = sum(item.get('word_count', 0) for item in metadata)

            return {
                "total_chunks": total_chunks,
                "total_words": total_words,
                "avg_words_per_chunk": total_words / total_chunks if total_chunks > 0 else 0,
                "model_name": rag_system.model_info.get("model_name", "unknown")
            }
        else:
            return {"error": "Metadata not found"}

    except Exception as e:
        return {"error": str(e)}

@app.get("/sources/{chunk_id}", tags=["Sources"])
async def get_source_content(chunk_id: int):
    """Láº¥y ná»™i dung cá»§a má»™t chunk"""

    if not rag_system:
        raise HTTPException(status_code=503, detail="RAG system not available")

    try:
        content = rag_system.get_chunk_content(chunk_id)
        if content:
            return {"chunk_id": chunk_id, "content": content}
        else:
            raise HTTPException(status_code=404, detail="Chunk not found")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Global variables for signal handling
server = None

def signal_handler(signum, frame):
    """Handle shutdown signals gracefully"""
    global server
    print(f"\nğŸ›‘ Nháº­n tÃ­n hiá»‡u {signum}, Ä‘ang dá»«ng server...")
    if server:
        server.should_exit = True
    print("âœ… Server Ä‘Ã£ dá»«ng!")
    sys.exit(0)

def run_server(host="0.0.0.0", port=8000, reload=False):
    """Cháº¡y server trá»±c tiáº¿p vá»›i signal handling tá»‘t"""
    global server

    # Setup signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    print(f"ğŸš€ Khá»Ÿi Ä‘á»™ng LegalAdvisor API server...")
    print(f"ğŸ“¡ Host: {host}")
    print(f"ğŸ”Œ Port: {port}")
    print(f"ğŸ”„ Reload: {reload}")
    print("ğŸ›‘ Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng server")
    print("=" * 50)

    try:
        # Táº¡o uvicorn config
        config = uvicorn.Config(
            app=app,  # Sá»­ dá»¥ng app instance trá»±c tiáº¿p thay vÃ¬ string
            host=host,
            port=port,
            reload=reload,
            log_level="info"
        )

        # Táº¡o server instance
        server = uvicorn.Server(config)

        print(f"ğŸ¯ Server config: {host}:{port} (reload: {reload})")

        # Cháº¡y server
        server.run()

    except Exception as e:
        print(f"âŒ Lá»—i khi khá»Ÿi Ä‘á»™ng server: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    # Cháº¡y server vá»›i cáº¥u hÃ¬nh Ä‘Ã£ parse á»Ÿ Ä‘áº§u file
    run_server(host=args.host, port=args.port, reload=False)
