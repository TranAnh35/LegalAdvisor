#!/usr/bin/env python3
"""
Gemini RAG implementation for LegalAdvisor
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional

from dotenv import load_dotenv
from ..retrieval.service import RetrievalService

# Do NOT initialize google.generativeai at import time.
# Gemini (google-generativeai) will be imported and configured lazily
# inside GeminiRAG._initialize_gemini() to avoid raising on module import
# when GOOGLE_API_KEY is not present (improves testability and CI).
GEMINI_MODEL = "gemini-2.0-flash-exp"

def _vietnamese_doc_title(type_code: str, number: str) -> str:
    """Chuyá»ƒn type+number thÃ nh tÃªn vÄƒn báº£n thÃ¢n thiá»‡n.
    VÃ­ dá»¥: ttlt-bca-btp-vksndtc-tandtc + 13/2012 ->
    "ThÃ´ng tÆ° liÃªn tá»‹ch 13/2012/TTLT-BCA-BTP-VKSNDTC-TANDTC"
    """
    if not type_code:
        return number or "VÄƒn báº£n phÃ¡p luáº­t"
    code = (type_code or '').lower()
    code_upper = (type_code or '').upper()
    mapping = {
        'nÄ‘-cp': 'Nghá»‹ Ä‘á»‹nh',
        'nd-cp': 'Nghá»‹ Ä‘á»‹nh',
        'tt': 'ThÃ´ng tÆ°',
        'tt-bca': 'ThÃ´ng tÆ°',
        'tt-byt': 'ThÃ´ng tÆ°',
        'ttlt': 'ThÃ´ng tÆ° liÃªn tá»‹ch',
        'ttlt-bca-btp-vksndtc-tandtc': 'ThÃ´ng tÆ° liÃªn tá»‹ch',
        'qÄ‘-ttg': 'Quyáº¿t Ä‘á»‹nh',
        'qd-ttg': 'Quyáº¿t Ä‘á»‹nh',
        'lh': 'Luáº­t',
        'qh': 'Luáº­t',
    }
    vn_type = mapping.get(code, code_upper)
    return f"{vn_type} {number}/{code_upper}"

def format_retrieved_docs(docs: List[Dict[str, Any]]) -> str:
    """Format retrieved documents vá»›i tÃªn luáº­t + Ä‘iá»u/khoáº£n/Ä‘iá»ƒm vÃ  tÃ³m táº¯t ngáº¯n.

    - Giá»¯ nguyÃªn dáº¥u '_' trong content Ä‘á»ƒ khá»›p embedding, nhÆ°ng chá»‰ khi khÃ´ng áº£nh hÆ°á»Ÿng Ä‘á»c hiá»ƒu.
    - TÄƒng snippet lÃªn 1200 kÃ½ tá»± Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh Ä‘áº§y Ä‘á»§ hÆ¡n.
    """
    formatted_docs: List[str] = []
    for i, doc in enumerate(docs, 1):
        corpus_id = doc.get('corpus_id') or ''
        type_code = doc.get('type') or ''
        number = doc.get('number') or ''
        year = doc.get('year') or ''
        suffix = doc.get('suffix') or ''
        dieu = f"Äiá»u {suffix}" if str(suffix).isdigit() else ''

        law_title = _vietnamese_doc_title(type_code, number)

        content = (doc.get('content') or '').strip()
        # Hiá»ƒn thá»‹ thÃ¢n thiá»‡n: thay '_' báº±ng ' ' chá»‰ trong pháº§n snippet Ä‘á»ƒ dá»… Ä‘á»c
        snippet = content[:1200].replace('_', ' ')
        suffix = '...' if len(content) > 1200 else ''

        formatted_docs.append(
            f"[Nguá»“n {i}] {law_title}{(' - ' + dieu) if dieu else ''} â€” `{corpus_id}`\n{snippet}{suffix}\n(Ä‘iá»ƒm: {doc.get('score', 0):.2f})"
        )
    return "\n\n".join(formatted_docs)

class GeminiRAG:
    """RAG implementation using Google's Gemini for legal question answering"""
    
    def __init__(self, use_gpu: bool = False):
        """Initialize the GeminiRAG system"""
        self.use_gpu = use_gpu
        self.retriever = None
        self.model = None
        self.metadata = {}
        
        # Initialize components
        self._initialize_retriever()
        self._initialize_gemini()
        
        print("âœ… GeminiRAG initialized successfully!")
    
    def _initialize_retriever(self):
        """Initialize unified RetrievalService"""
        try:
            self.retriever = RetrievalService(use_gpu=self.use_gpu)
            # Mirror thÃ´ng tin phá»¥c vá»¥ /stats
            self.model_info = getattr(self.retriever, 'model_info', {})
            self.metadata = getattr(self.retriever, 'metadata', {})
        except Exception as e:
            raise RuntimeError(f"Failed to initialize retriever: {str(e)}")
    
    def _initialize_gemini(self):
        """Initialize the Gemini model"""
        try:
            # Load env and require API key at runtime (not at import time)
            load_dotenv()
            google_api_key = os.getenv('GOOGLE_API_KEY')
            if not google_api_key:
                raise RuntimeError("GOOGLE_API_KEY not found in environment variables")

            # Import and configure google.generativeai lazily so importing this
            # module (or running tests that mock RAG) does not fail when the key
            # is not set.
            import google.generativeai as genai  # imported here intentionally

            genai.configure(api_key=google_api_key)

            # Initialize the Gemini model
            generation_config = {
                "temperature": 0.1,  # tháº¥p hÆ¡n Ä‘á»ƒ giáº£m suy diá»…n
                "top_p": 0.9,
                "top_k": 40,
                "max_output_tokens": 2048,
            }

            safety_settings = [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_NONE"
                },
            ]

            self.model = genai.GenerativeModel(
                model_name=GEMINI_MODEL,
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
        except Exception as e:
            raise RuntimeError(f"Failed to initialize Gemini model: {str(e)}")
    
    def retrieve_documents(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """Retrieve relevant documents for a query"""
        try:
            if not self.retriever:
                return []
            return self.retriever.retrieve(query, top_k=top_k)
        except Exception as e:
            print(f"Error retrieving documents: {str(e)}")
            return []

    def _get_chunk_content_by_id(self, chunk_id: int) -> Optional[str]:
        """Äá»c content theo chunk_id tá»« SQLite hoáº·c Parquet (lazy)."""
        try:
            if not self.retriever:
                return None
            return self.retriever.get_chunk_content(int(chunk_id))
        except Exception:
            return None
    
    def generate_response(self, question: str, context: str = None, **kwargs) -> str:
        """Generate a response using Gemini"""
        try:
            # Ensure Gemini model is initialized at call-time. This allows
            # importing the module (e.g., in tests) without GOOGLE_API_KEY set.
            if not getattr(self, 'model', None):
                try:
                    self._initialize_gemini()
                except Exception as e:
                    # Fail gracefully: return an informative message rather than
                    # raising at import or runtime in user-facing paths.
                    print(f"Error initializing Gemini: {e}")
                    return "Xin lá»—i, há»‡ thá»‘ng chÆ°a cáº¥u hÃ¬nh mÃ´ hÃ¬nh ngÃ´n ngá»¯. Vui lÃ²ng thiáº¿t láº­p GOOGLE_API_KEY."

            # Prepare the prompt
            if context:
                prompt = f"""
                Báº¡n lÃ  trá»£ lÃ½ phÃ¡p lÃ½ tiáº¿ng Viá»‡t. Tráº£ lá»i CHá»ˆ dá»±a vÃ o ngá»¯ cáº£nh sau.
                - KHÃ”NG chÃ¨n mÃ£ nguá»“n hay corpus-id vÃ o pháº§n tráº£ lá»i. KHÃ”NG dÃ¹ng ngoáº·c Ä‘Æ¡n Ä‘á»ƒ liá»‡t kÃª mÃ£ nguá»“n.
                - Háº¡n cháº¿ suy diá»…n. Chá»‰ khi ngá»¯ cáº£nh khÃ´ng nÃªu quy Ä‘á»‹nh trá»±c tiáº¿p má»›i nÃ³i "KhÃ´ng Ä‘á»§ cÄƒn cá»© trong nguá»“n Ä‘Ã£ trÃ­ch" vÃ  gá»£i Ã½ vÄƒn báº£n cáº§n tra thÃªm.
                - CÃ¢u tráº£ lá»i ngáº¯n gá»n, 3-5 gáº¡ch Ä‘áº§u dÃ²ng, dÃ¹ng ngÃ´n ngá»¯ tá»± nhiÃªn, dá»… hiá»ƒu.

                Ngá»¯ cáº£nh (Ä‘Ã£ kÃ¨m corpus-id):
                {context}

                CÃ¢u há»i: {question}
                """
            else:
                prompt = f"""
                Báº¡n lÃ  má»™t trá»£ lÃ½ phÃ¡p lÃ½ thÃ´ng minh. HÃ£y tráº£ lá»i cÃ¢u há»i sau Ä‘Ã¢y:
                
                CÃ¢u há»i: {question}
                
                Náº¿u báº¡n khÃ´ng cháº¯c cháº¯n vá» cÃ¢u tráº£ lá»i, hÃ£y nÃ³i rÃµ Ä‘iá»u Ä‘Ã³.
                """
            
            # Generate response
            response = self.model.generate_content(prompt)

            # Return the generated text
            return response.text
            
        except Exception as e:
            print(f"Error generating response: {str(e)}")
            return "Xin lá»—i, tÃ´i gáº·p lá»—i khi xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i sau."
    
    def ask(self, question: str, top_k: int = 3) -> Dict[str, Any]:
        """Process a question and return the answer with sources"""
        start_time = time.time()
        
        try:
            # Step 1: Retrieve relevant documents
            retrieved_docs = self.retrieve_documents(question, top_k=top_k)
            
            # Step 2: Format context from retrieved documents
            context = format_retrieved_docs(retrieved_docs) if retrieved_docs else None
            
            # Step 3: Generate response using Gemini
            answer = self.generate_response(question, context)

            # KhÃ´ng thÃªm block tham kháº£o vÃ o cÃ¢u tráº£ lá»i Ä‘á»ƒ trÃ¡nh trÃ¹ng vá»›i UI. UI sáº½ hiá»ƒn thá»‹ sources.
            
            # Prepare response
            response = {
                'question': question,
                'answer': answer,
                'sources': retrieved_docs,
                'num_sources': int(len(retrieved_docs)),
                'status': 'success',
                'processing_time': time.time() - start_time
            }
            
            return response
            
        except Exception as e:
            return {
                'question': question,
                'answer': f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i: {str(e)}",
                'sources': [],
                'num_sources': int(0),
                'status': 'error',
                'error': str(e),
                'processing_time': time.time() - start_time
            }

    def get_chunk_content(self, chunk_id: int) -> Optional[str]:
        """Tráº£ vá» ná»™i dung chunk theo id tá»« SQLite/Parquet (Æ°u tiÃªn)."""
        return self._get_chunk_content_by_id(chunk_id)

def test_gemini_rag():
    """Test the GeminiRAG implementation"""
    try:
        print("ğŸš€ Testing GeminiRAG...")
        
        # Initialize RAG
        rag = GeminiRAG(use_gpu=False)
        
        # Test query
        query = "Äiá»u kiá»‡n Ä‘á»ƒ thÃ nh láº­p doanh nghiá»‡p tÆ° nhÃ¢n?"
        print(f"\nğŸ¤– CÃ¢u há»i: {query}")
        
        # Get response
        response = rag.ask(query, top_k=3)
        
        # Print results
        print("\nğŸ“ CÃ¢u tráº£ lá»i:")
        print(response['answer'])
        
        print(f"\nğŸ” Nguá»“n tham kháº£o ({response['num_sources']}):")
        for i, source in enumerate(response['sources'], 1):
            # TrÃ¡nh KeyError: metadata hiá»‡n khÃ´ng cÃ³ 'title'
            corpus_id = source.get('corpus_id') or '(khÃ´ng cÃ³ corpus_id)'
            score = source.get('score', 0.0)
            print(f"{i}. {corpus_id} (Äiá»ƒm: {score:.2f})")
        
        print("\nâœ… Test completed successfully!")
        
    except Exception as e:
        print(f"âŒ Test failed: {str(e)}")

if __name__ == "__main__":
    test_gemini_rag()
